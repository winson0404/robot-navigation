project_name: CustomNet
experiment_name: default
dataset:
  dataset_path: C:\Users\User\projects\data\
  targets:
  - front
  - left
  - right
  - previous
  image_size: [320, 240]
  subset: -1
random_seed: 42
device: 'cuda'
model:
  name: 'CustomNet'  # 'MobileNetV3_large' or 'AlexNet' or 'CustomNet'
  pretrained: False
  freezed: False
  start_epoch: 0
  full_frame: False
optimizer:
  optimizer: ["sgd", "adam", "rmsprop"] # adam, sgd, rmsprop
  lr: [0.001, 0.005, 0.0005, 0.0001]
  momentum: [0.5, 0.6, 0.7, 0.8, 0.9]
  weight_decay: [0, 0.0001, 0.0005, 0,001, 0.005]
scheduler:
  start_factor: [0.001, 0.005, 0.05, 0.01]
train_params:
  epochs: [20, 30, 40]
  num_workers: 16
  train_batch_size: [16, 32, 64]
  validation_batch_size: [16, 32, 64]
  # early_stopping: 10
  dropout: [0, 0.25, 0.5, 0.75, 0.1]
metric_params:
  metrics: ['accuracy', 'f1_score', 'precision', 'recall']
  average: 'weighted'
nas:
  conv_layers: [1, 2, 3, 4, 5]
  out_channels: [16, 32, 64, 128, 256]
  kernel_size: [3, 5, 7]
  stride: [1, 2, 3]
  padding: [0, 1, 2]
  # dilation: [1, 2, 3]
  # groups: [1, 2, 3]
  # bias: [True, False]
  activation: ['relu', 'leaky_relu', 'sigmoid', 'tanh']
  pool_type: ['max', 'avg']
  pool_kernel_size: [2, 3, 4]
  pool_stride: [1, 2, 3]
  pool_padding: [0, 1, 2]
  # pool_dilation: [1, 2, 3]
  # pool_return_indices: [True, False]
  # pool_ceil_mode: [True, False]
  # pool_count_include_pad: [True, False]
  # pool_divisor_override: [1, 2, 3]
  # pool_padding_mode: ['zeros', 'reflect', 'replicate', 'circular']
  dropout: [0, 0.25, 0.5, 0.75, 0.1]
  batch_norm: [True, False]
  # batch_norm_affine: [True, False]
  # batch_norm_track_running_stats: [True, False]
  # batch_norm_momentum: [0.1, 0.2, 0.3, 0.4, 0.5]
  # batch_norm_eps: [1e-05, 1e-04, 1e-03, 1e-02, 1e-01]
  # batch_norm_track_running_stats: [True, False]
  # batch_norm_momentum: [0.1, 0.2, 0.3, 0.4, 0.5]
  # batch_norm_eps: [1e-05, 1e-04, 1e-03, 1e-02, 1e-01]
  linear_layers: [1, 2, 3, 4, 5]
  linear_in_features: [1, 2, 3, 4, 5]
  linear_out_features: [1, 2, 3, 4, 5]
  linear_bias: [True, False]
  linear_dropout: [0, 0.25, 0.5, 0.75, 0.1]
  # linear_batch_norm: [True, False]
  # linear_batch_norm_affine: [True, False]
  # linear_batch_norm_track_running_stats: [True, False]
  # linear_batch_norm_momentum: [0.1, 0.2, 0.3, 0.4, 0.5]
  # linear_batch_norm_eps: [1e-05, 1e-04, 1e-03, 1e-02, 1e-01]
  linear_activation: ['relu', 'leaky_relu', 'elu', 'selu', 'sigmoid', 'tanh']

